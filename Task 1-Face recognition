import React, { useState, useRef, useEffect } from 'react';
import { Camera, Upload, User, Users, AlertCircle, CheckCircle, X } from 'lucide-react';

const FaceDetectionApp = () => {
  const [mode, setMode] = useState('upload');
  const [image, setImage] = useState(null);
  const [detectionMethod, setDetectionMethod] = useState('blazeface');
  const [processing, setProcessing] = useState(false);
  const [detectedFaces, setDetectedFaces] = useState([]);
  const [registeredFaces, setRegisteredFaces] = useState([]);
  const [recognitionEnabled, setRecognitionEnabled] = useState(false);
  const [error, setError] = useState('');
  const [modelLoaded, setModelLoaded] = useState(false);
  
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const imageCanvasRef = useRef(null);
  const streamRef = useRef(null);
  const animationRef = useRef(null);
  const blazefaceModelRef = useRef(null);

  // Load BlazeFace model
  useEffect(() => {
    const loadModel = async () => {
      try {
        const script = document.createElement('script');
        script.src = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0';
        document.head.appendChild(script);
        
        script.onload = async () => {
          const blazefaceScript = document.createElement('script');
          blazefaceScript.src = 'https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7';
          document.head.appendChild(blazefaceScript);
          
          blazefaceScript.onload = async () => {
            blazefaceModelRef.current = await window.blazeface.load();
            setModelLoaded(true);
          };
        };
      } catch (err) {
        setError('Failed to load face detection model');
      }
    };
    
    loadModel();
    
    return () => {
      stopCamera();
    };
  }, []);

  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { width: 640, height: 480 } 
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        streamRef.current = stream;
        videoRef.current.play();
        detectFacesRealtime();
      }
    } catch (err) {
      setError('Camera access denied');
    }
  };

  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
  };

  const detectFacesRealtime = async () => {
    if (!videoRef.current || !canvasRef.current || !blazefaceModelRef.current) return;
    
    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    
    if (video.readyState === 4) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      const predictions = await blazefaceModelRef.current.estimateFaces(canvas, false);
      
      predictions.forEach(prediction => {
        const start = prediction.topLeft;
        const end = prediction.bottomRight;
        const size = [end[0] - start[0], end[1] - start[1]];
        
        ctx.strokeStyle = '#00ff00';
        ctx.lineWidth = 3;
        ctx.strokeRect(start[0], start[1], size[0], size[1]);
        
        // Draw landmarks
        if (prediction.landmarks) {
          ctx.fillStyle = '#ff0000';
          prediction.landmarks.forEach(landmark => {
            ctx.beginPath();
            ctx.arc(landmark[0], landmark[1], 3, 0, 2 * Math.PI);
            ctx.fill();
          });
        }
        
        // Recognition label
        if (recognitionEnabled && registeredFaces.length > 0) {
          const recognized = recognizeFace(prediction);
          if (recognized) {
            ctx.fillStyle = '#00ff00';
            ctx.fillRect(start[0], start[1] - 30, size[0], 30);
            ctx.fillStyle = '#000000';
            ctx.font = '16px Arial';
            ctx.fillText(recognized.name, start[0] + 5, start[1] - 10);
          }
        }
      });
      
      setDetectedFaces(predictions);
    }
    
    animationRef.current = requestAnimationFrame(detectFacesRealtime);
  };

  const handleImageUpload = (e) => {
    const file = e.target.files[0];
    if (file) {
      const reader = new FileReader();
      reader.onload = (event) => {
        setImage(event.target.result);
        setDetectedFaces([]);
      };
      reader.readAsDataURL(file);
    }
  };

  const detectFacesInImage = async () => {
    if (!image || !blazefaceModelRef.current) return;
    
    setProcessing(true);
    setError('');
    
    try {
      const img = new Image();
      img.src = image;
      
      img.onload = async () => {
        const canvas = imageCanvasRef.current;
        const ctx = canvas.getContext('2d');
        
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.drawImage(img, 0, 0);
        
        const predictions = await blazefaceModelRef.current.estimateFaces(canvas, false);
        
        // Draw detections
        predictions.forEach((prediction, idx) => {
          const start = prediction.topLeft;
          const end = prediction.bottomRight;
          const size = [end[0] - start[0], end[1] - start[1]];
          
          ctx.strokeStyle = '#00ff00';
          ctx.lineWidth = 3;
          ctx.strokeRect(start[0], start[1], size[0], size[1]);
          
          // Draw confidence
          ctx.fillStyle = '#00ff00';
          ctx.fillRect(start[0], start[1] - 25, 100, 25);
          ctx.fillStyle = '#000000';
          ctx.font = '14px Arial';
          ctx.fillText(`Face ${idx + 1}`, start[0] + 5, start[1] - 8);
          
          // Draw landmarks
          if (prediction.landmarks) {
            ctx.fillStyle = '#ff0000';
            prediction.landmarks.forEach(landmark => {
              ctx.beginPath();
              ctx.arc(landmark[0], landmark[1], 3, 0, 2 * Math.PI);
              ctx.fill();
            });
          }
          
          // Recognition
          if (recognitionEnabled && registeredFaces.length > 0) {
            const recognized = recognizeFace(prediction);
            if (recognized) {
              ctx.fillStyle = '#ffff00';
              ctx.fillRect(start[0], end[1] + 5, size[0], 25);
              ctx.fillStyle = '#000000';
              ctx.fillText(recognized.name, start[0] + 5, end[1] + 20);
            }
          }
        });
        
        setDetectedFaces(predictions);
        setProcessing(false);
      };
    } catch (err) {
      setError('Face detection failed');
      setProcessing(false);
    }
  };

  const registerFace = () => {
    if (detectedFaces.length === 0) {
      setError('No faces detected to register');
      return;
    }
    
    const name = prompt('Enter name for this face:');
    if (name) {
      const faceData = {
        id: Date.now(),
        name,
        embedding: extractFaceEmbedding(detectedFaces[0]),
        timestamp: new Date().toISOString()
      };
      
      setRegisteredFaces([...registeredFaces, faceData]);
      setError('');
    }
  };

  const extractFaceEmbedding = (face) => {
    // Simplified embedding extraction using landmarks and bounding box
    const features = [];
    if (face.landmarks) {
      face.landmarks.forEach(landmark => {
        features.push(landmark[0], landmark[1]);
      });
    }
    features.push(
      face.topLeft[0], face.topLeft[1],
      face.bottomRight[0], face.bottomRight[1]
    );
    return features;
  };

  const recognizeFace = (face) => {
    if (registeredFaces.length === 0) return null;
    
    const embedding = extractFaceEmbedding(face);
    let bestMatch = null;
    let minDistance = Infinity;
    
    registeredFaces.forEach(registered => {
      const distance = euclideanDistance(embedding, registered.embedding);
      if (distance < minDistance && distance < 150) {
        minDistance = distance;
        bestMatch = registered;
      }
    });
    
    return bestMatch;
  };

  const euclideanDistance = (a, b) => {
    const minLen = Math.min(a.length, b.length);
    let sum = 0;
    for (let i = 0; i < minLen; i++) {
      sum += Math.pow(a[i] - b[i], 2);
    }
    return Math.sqrt(sum);
  };

  const removeFace = (id) => {
    setRegisteredFaces(registeredFaces.filter(f => f.id !== id));
  };

  useEffect(() => {
    if (mode === 'camera' && modelLoaded) {
      startCamera();
    } else {
      stopCamera();
    }
  }, [mode, modelLoaded]);

  useEffect(() => {
    if (image && modelLoaded) {
      detectFacesInImage();
    }
  }, [image, recognitionEnabled, registeredFaces]);

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 text-white p-6">
      <div className="max-w-7xl mx-auto">
        <div className="text-center mb-8">
          <h1 className="text-4xl font-bold mb-2 bg-gradient-to-r from-blue-400 to-purple-400 bg-clip-text text-transparent">
            AI Face Detection & Recognition
          </h1>
          <p className="text-gray-300">Powered by BlazeFace & Custom Recognition</p>
        </div>

        {!modelLoaded && (
          <div className="bg-yellow-500/20 border border-yellow-500 rounded-lg p-4 mb-6 text-center">
            <AlertCircle className="inline mr-2" />
            Loading AI model...
          </div>
        )}

        {error && (
          <div className="bg-red-500/20 border border-red-500 rounded-lg p-4 mb-6">
            <AlertCircle className="inline mr-2" />
            {error}
          </div>
        )}

        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
          {/* Controls */}
          <div className="lg:col-span-1 space-y-4">
            <div className="bg-white/10 backdrop-blur-lg rounded-lg p-6 border border-white/20">
              <h2 className="text-xl font-bold mb-4 flex items-center">
                <Camera className="mr-2" />
                Mode Selection
              </h2>
              
              <div className="space-y-3">
                <button
                  onClick={() => setMode('camera')}
                  className={`w-full p-3 rounded-lg transition ${
                    mode === 'camera'
                      ? 'bg-blue-500 text-white'
                      : 'bg-white/5 hover:bg-white/10'
                  }`}
                  disabled={!modelLoaded}
                >
                  <Camera className="inline mr-2" size={20} />
                  Live Camera
                </button>
                
                <button
                  onClick={() => setMode('upload')}
                  className={`w-full p-3 rounded-lg transition ${
                    mode === 'upload'
                      ? 'bg-blue-500 text-white'
                      : 'bg-white/5 hover:bg-white/10'
                  }`}
                  disabled={!modelLoaded}
                >
                  <Upload className="inline mr-2" size={20} />
                  Upload Image
                </button>
              </div>

              {mode === 'upload' && (
                <div className="mt-4">
                  <input
                    type="file"
                    accept="image/*"
                    onChange={handleImageUpload}
                    className="w-full p-2 bg-white/5 rounded border border-white/20"
                  />
                </div>
              )}
            </div>

            <div className="bg-white/10 backdrop-blur-lg rounded-lg p-6 border border-white/20">
              <h2 className="text-xl font-bold mb-4 flex items-center">
                <User className="mr-2" />
                Recognition
              </h2>
              
              <div className="space-y-3">
                <label className="flex items-center space-x-2">
                  <input
                    type="checkbox"
                    checked={recognitionEnabled}
                    onChange={(e) => setRecognitionEnabled(e.target.checked)}
                    className="w-4 h-4"
                  />
                  <span>Enable Recognition</span>
                </label>

                <button
                  onClick={registerFace}
                  disabled={detectedFaces.length === 0}
                  className="w-full p-3 bg-green-500 hover:bg-green-600 disabled:bg-gray-600 rounded-lg transition"
                >
                  Register Current Face
                </button>
              </div>

              <div className="mt-4">
                <div className="text-sm text-gray-300 mb-2">
                  Registered: {registeredFaces.length}
                </div>
                <div className="space-y-2 max-h-40 overflow-y-auto">
                  {registeredFaces.map((face) => (
                    <div
                      key={face.id}
                      className="flex items-center justify-between bg-white/5 p-2 rounded"
                    >
                      <span className="text-sm">{face.name}</span>
                      <button
                        onClick={() => removeFace(face.id)}
                        className="text-red-400 hover:text-red-300"
                      >
                        <X size={16} />
                      </button>
                    </div>
                  ))}
                </div>
              </div>
            </div>

            <div className="bg-white/10 backdrop-blur-lg rounded-lg p-6 border border-white/20">
              <h2 className="text-xl font-bold mb-4 flex items-center">
                <Users className="mr-2" />
                Detection Stats
              </h2>
              
              <div className="space-y-2 text-sm">
                <div className="flex justify-between">
                  <span>Faces Detected:</span>
                  <span className="font-bold">{detectedFaces.length}</span>
                </div>
                <div className="flex justify-between">
                  <span>Model:</span>
                  <span className="font-bold">BlazeFace</span>
                </div>
                <div className="flex justify-between">
                  <span>Status:</span>
                  <span className={`font-bold ${modelLoaded ? 'text-green-400' : 'text-yellow-400'}`}>
                    {modelLoaded ? 'Ready' : 'Loading'}
                  </span>
                </div>
              </div>
            </div>
          </div>

          {/* Display Area */}
          <div className="lg:col-span-2">
            <div className="bg-white/10 backdrop-blur-lg rounded-lg p-6 border border-white/20">
              <h2 className="text-xl font-bold mb-4">
                {mode === 'camera' ? 'Live Detection' : 'Image Analysis'}
              </h2>
              
              <div className="relative bg-black rounded-lg overflow-hidden" style={{ minHeight: '400px' }}>
                {mode === 'camera' ? (
                  <>
                    <video
                      ref={videoRef}
                      className="absolute inset-0 w-full h-full object-contain"
                      style={{ display: 'none' }}
                    />
                    <canvas
                      ref={canvasRef}
                      className="w-full h-full object-contain"
                    />
                  </>
                ) : (
                  <canvas
                    ref={imageCanvasRef}
                    className="w-full h-full object-contain"
                  />
                )}
                
                {!modelLoaded && (
                  <div className="absolute inset-0 flex items-center justify-center">
                    <div className="text-center">
                      <div className="animate-spin rounded-full h-16 w-16 border-b-2 border-white mx-auto mb-4"></div>
                      <p>Loading AI Model...</p>
                    </div>
                  </div>
                )}
                
                {modelLoaded && mode === 'upload' && !image && (
                  <div className="absolute inset-0 flex items-center justify-center">
                    <p className="text-gray-400">Upload an image to start detection</p>
                  </div>
                )}
              </div>

              {processing && (
                <div className="mt-4 text-center">
                  <div className="animate-pulse">Processing...</div>
                </div>
              )}
            </div>
          </div>
        </div>

        <div className="mt-8 bg-white/10 backdrop-blur-lg rounded-lg p-6 border border-white/20">
          <h2 className="text-xl font-bold mb-4">Features & Techniques</h2>
          <div className="grid grid-cols-1 md:grid-cols-3 gap-4 text-sm">
            <div className="bg-white/5 p-4 rounded-lg">
              <h3 className="font-bold mb-2 text-blue-400">BlazeFace Detection</h3>
              <p className="text-gray-300">Ultra-fast face detection optimized for mobile and web applications with landmark detection.</p>
            </div>
            <div className="bg-white/5 p-4 rounded-lg">
              <h3 className="font-bold mb-2 text-purple-400">Custom Recognition</h3>
              <p className="text-gray-300">Face recognition using embedding extraction and distance-based matching algorithms.</p>
            </div>
            <div className="bg-white/5 p-4 rounded-lg">
              <h3 className="font-bold mb-2 text-green-400">Real-time Processing</h3>
              <p className="text-gray-300">Live video stream analysis with continuous face detection and recognition capabilities.</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default FaceDetectionApp;
